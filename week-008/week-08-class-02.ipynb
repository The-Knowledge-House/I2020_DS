{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #000;\n",
    "            color: #FFF;\n",
    "            margin: 0px;\n",
    "                padding: 10px 0px 20px 0px;\n",
    "            text-align: center; \n",
    "                \">\n",
    "    <h1>Week 8 - Class 2 - 11/03</h1>\n",
    "</div>\n",
    "\n",
    "## Objectives for this week:\n",
    "* HTML/CSS Review\n",
    "* URLLib3/Requests/BS4\n",
    "* Web Crawling\n",
    "* JSON data in Python\n",
    "* Reading/Writing to Files\n",
    "\n",
    "## Today's Agenda\n",
    "* Web Crawling/Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Create a function that takes a dictionary and returns two lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the following function defintion so it \n",
    "# so no AssertionError is thrown\n",
    "def ex1a(arg):\n",
    "    keys = [key for key in arg.keys()]\n",
    "    values = [value for value in arg.values()]\n",
    "    return (keys,values)\n",
    "  \n",
    "\n",
    "assert(ex1a({'a':1,'b':2}) == (['a','b'], [1,2]))\n",
    "assert(ex1a({1:'a', 2:'b'}) == ([1,2], ['a', 'b']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Create a function that takes two sets and returns a list of the shared elements.\n",
    "\n",
    "Use `for` loops. Do not use any set methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the following code so the cell\n",
    "# runs without error\n",
    "def ex1b(s,t):\n",
    "    pass\n",
    "\n",
    "# use the following code to check your solution \n",
    "try:\n",
    "    assert(ex1b({}, {1}) == [])\n",
    "    assert(ex1b({1,2}, {2,3}) == [2])\n",
    "    assert(ex1b({1,2,3,4}, {3,4,5,6}) == [3,4])\n",
    "    print(\"code runs without error\")\n",
    "except AssertionError:\n",
    "    print(\"code is incorrect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Create the code to test the following function.\n",
    "\n",
    "Hint: Take a look at how it's set up in _**a**_ and _**b**_ and use either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def ex1c(g):\n",
    "    if isinstance(g, list):\n",
    "        if len(g) == 0:\n",
    "            return []\n",
    "        else:\n",
    "            return reduce(lambda x,y: x+y, g)\n",
    "\n",
    "# Use the following test cases in your solution:\n",
    "ex1c(\"sd\")\n",
    "ex1c([])\n",
    "ex1c([0])\n",
    "ex1c([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More on Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `requests.get(url)` -> `Response()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get('https://www.python.org')\n",
    "print(r.status_code)\n",
    "print(r.text) # similar to r.content but produces the text of the response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `requests.post(url, data)` -> `Response()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "payload = dict(key1='value1', key2='value2')\n",
    "\n",
    "r = requests.post('https://httpbin.org/post', data=payload)\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `requests.Request(method, url, headers)` -> `Response()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generic requests\n",
    "\n",
    "import requests\n",
    "\n",
    "# Request(method=None, url=None, headers=None, files=None, data=None, params=None, auth=None, cookies=None, hooks=None, json=None)\n",
    "requests.Request('GET', 'https://httpbin.org/get')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `requests.Response()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# responses are instances of the class Response\n",
    "\n",
    "resp = requests.Response()\n",
    "\n",
    "[i for i in dir(resp) if not i.startswith('_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More on BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BeautifulSoup(html, parser)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an instance of soup\n",
    "\n",
    "html = \"<h1>hello</h1><h1>world</h1>\"\n",
    "soup = BeautifulSoup(html)\n",
    "\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accesssing text within a tag\n",
    "\n",
    "html = \"<h1>hello</h1>\"\n",
    "soup = BeautifulSoup(html)\n",
    "\n",
    "h1 = soup.find('h1')\n",
    "\n",
    "h1.contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `soup.find(tag)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(\"<h1>hello</h1><h1>world</h1>\")\n",
    "soup.find('h1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `soup.findAll(tag)`/`soup.find_all(tag)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(\"<h1>hello</h1><h1>world</h1>\")\n",
    "soup.findAll('h1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(\"<h1>hello</h1><h1>world</h1>\")\n",
    "soup.find_all('h1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `soup.prettify()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \\\n",
    "\"\"\"\n",
    "<html><head></head><body><h1>hello world</h1><p>paragraph</p></body></html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html)\n",
    "print(soup.prettify())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `soup.strings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \\\n",
    "\"\"\"\n",
    "<html><head></head><body><h1>hello world</h1><p>paragraph</p></body></html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html)\n",
    "print(list(soup.strings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \\\n",
    "\"\"\"\n",
    "<html>\n",
    "  <head>\n",
    "    <title>our webpage</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h1>hello world</h1>\n",
    "    <p>paragraph</p>\n",
    "    <ul>\n",
    "      <li><a href='#'>link 1</a></li>\n",
    "      <li><a href='#'>link 2</a></li>\n",
    "      <li><a href='#'>link 3</a></li>\n",
    "    </ul>\n",
    "    <p id='ident'>hello world</p>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html)\n",
    "\n",
    "print(\"\\n --print html tag-- \\n\")\n",
    "print(soup.html)\n",
    "print(\"\\n --print title tag-- \\n\")\n",
    "print(soup.title)\n",
    "print(soup.title.string)\n",
    "print(\"\\n --print head tag-- \\n\")\n",
    "print(soup.head)\n",
    "print(\"\\n --print li tag-- \\n\")\n",
    "# this will return the first one found\n",
    "print(soup.li)\n",
    "print(\"\\n --print all li tags-- \\n\")\n",
    "print(soup.findAll('li'))\n",
    "print(\"\\n --print specific id-- \\n\")\n",
    "print(soup.find(id='ident'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `Tag` objects:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `get` with a `Tag` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \\\n",
    "\"\"\"\n",
    "<html>\n",
    "  <head>\n",
    "    <title>our webpage</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h1>hello world</h1>\n",
    "    <p>paragraph</p>\n",
    "    <ul>\n",
    "      <li><a href='#' id='link1'>link 1</a></li>\n",
    "      <li><a href='#' id='link2'>link 2</a></li>\n",
    "      <li><a href='#' id='link3'>link 3</a></li>\n",
    "    </ul>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html)\n",
    "\n",
    "lis = soup.findAll('li')\n",
    "\n",
    "for li in lis:\n",
    "    print(li.a)\n",
    "    \n",
    "for li in lis:\n",
    "    print(li.a.get('href'))\n",
    "    \n",
    "for li in lis:\n",
    "    print(li.a.get('id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternatively, we can use indexing instead of get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \\\n",
    "\"\"\"\n",
    "<html>\n",
    "  <head>\n",
    "    <title>our webpage</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h1>hello world</h1>\n",
    "    <p>paragraph</p>\n",
    "    <ul>\n",
    "      <li><a href='#' id='link1'>link 1</a></li>\n",
    "      <li><a href='#' id='link2'>link 2</a></li>\n",
    "      <li><a href='#' id='link3'>link 3</a></li>\n",
    "    </ul>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html)\n",
    "\n",
    "anchors = soup.findAll('a')\n",
    "\n",
    "print(anchors)\n",
    "print()\n",
    "print(anchors[1])\n",
    "print()\n",
    "print(anchors[1]['href'])\n",
    "print(anchors[1]['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traversing html using tags\n",
    "\n",
    "Using `parent`, `children` and `descendents` with `Tag`\n",
    "\n",
    "To move upwards in the html tree, use `.parent` or `.parents`.  \n",
    "\n",
    "To move downwards in the html tree, use `.children` or `.descendants`.   \n",
    "\n",
    "To move sideways in the html tree, use `.next_sibling` or `.previous_sibling`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.parent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .parent example\n",
    "\n",
    "html = \\\n",
    "\"\"\"\n",
    "<html>\n",
    "  <head>\n",
    "    <title>our webpage</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h1>hello world</h1>\n",
    "    <p>paragraph</p>\n",
    "    <ul>\n",
    "      <li><a href='#' id='link1'>link 1</a></li>\n",
    "      <li><a href='#' id='link2'>link 2</a></li>\n",
    "      <li><a href='#' id='link3'>link 3</a></li>\n",
    "    </ul>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html)\n",
    "\n",
    "ul = soup.ul\n",
    "\n",
    "ul.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.parents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \\\n",
    "\"\"\"\n",
    "<html>\n",
    "  <head>\n",
    "    <title>our webpage</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h1>hello world</h1>\n",
    "    <p>paragraph</p>\n",
    "    <ul>\n",
    "      <li><a href='#' id='link1'>link 1</a></li>\n",
    "      <li><a href='#' id='link2'>link 2</a></li>\n",
    "      <li><a href='#' id='link3'>link 3</a></li>\n",
    "    </ul>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html)\n",
    "\n",
    "ul = soup.ul\n",
    "\n",
    "for parent in ul.parents:\n",
    "    print(parent)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \\\n",
    "\"\"\"\n",
    "<html>\n",
    "  <head>\n",
    "    <title>our webpage</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h1>hello world</h1>\n",
    "    <p>paragraph</p>\n",
    "    <ul>\n",
    "      <li><a href='#' id='link1'>link 1</a></li>\n",
    "      <li><a href='#' id='link2'>link 2</a></li>\n",
    "      <li><a href='#' id='link3'>link 3</a></li>\n",
    "    </ul>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html)\n",
    "\n",
    "ul = soup.ul\n",
    "\n",
    "for child in ul.children:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.children` vs `.descendents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = (\"<html><head><title>our webpage</title></head><body><h1>hello world</h1>\"\n",
    "       \"<p>paragraph</p><ul><li><a href='#' id='link1'>link 1</a></li><li>\"\n",
    "       \"<a href='#' id='link2'>link 2</a></li><li><a href='#' id='link3'>link 3</a>\"\n",
    "        \"</li></ul></body></html>\")\n",
    "\n",
    "soup = BeautifulSoup(html)\n",
    "\n",
    "body = soup.body\n",
    "\n",
    "for child in body.children:\n",
    "    print(child)\n",
    "print(\"--------------------\")\n",
    "for descendant in body.descendants:\n",
    "    print(descendant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### siblings using `.next_sibling` and `.previous_sibling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \\\n",
    "\"\"\"\n",
    "<html>\n",
    "  <head>\n",
    "    <title>our webpage</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h1>hello world</h1>\n",
    "    <p>paragraph</p>\n",
    "    <ul>\n",
    "      <li><a href='#' id='link1'>link 1</a></li>\n",
    "      <li><a href='#' id='link2'>link 2</a></li>\n",
    "      <li><a href='#' id='link3'>link 3</a></li>\n",
    "    </ul>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html)\n",
    "li = soup.findAll('li')[1]\n",
    "\n",
    "print(list(li.previous_siblings))\n",
    "print()\n",
    "print(list(li.previous_sibling))\n",
    "print()\n",
    "print(li)\n",
    "print()\n",
    "print(list(li.next_sibling))\n",
    "print()\n",
    "print(list(li.next_siblings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping/Crawling\n",
    "\n",
    "\n",
    "\n",
    "#### Crawling - automated code that navigates web pages.\n",
    "#### Scraping - automated code that scrapes data from specific pages\n",
    "\n",
    "Usually, you will need a combination of both to do anything useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scraping `a` tags for links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.theknowledgehouse.org\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a_tags = soup.find_all('a')\n",
    "a_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter a tags\n",
    "links = []\n",
    "for anchor in a_tags:\n",
    "    try:\n",
    "        if (link := anchor['href']).startswith('http'):\n",
    "            links.append(link)\n",
    "        else:\n",
    "            links.append(url + link)\n",
    "    except KeyError:\n",
    "        continue\n",
    "\n",
    "for link in links:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create functions\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def get_links(url):\n",
    "    resp = requests.get(url)\n",
    "    soup = BeautifulSoup(resp.text)\n",
    "    a_tags = soup.find_all('a')\n",
    "    links = []\n",
    "    for anchor in a_tags:\n",
    "        try:\n",
    "            if (link := anchor['href']).startswith('http'):\n",
    "                links.append(link)\n",
    "            else:\n",
    "                links.append(url + link)\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return links\n",
    "\n",
    "get_links('http://www.cnn.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping - code that  pulls information off of web pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politico = \"https://www.politico.com/2020-election/results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(politico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = soup.findAll('div')\n",
    "\n",
    "for i in tags:\n",
    "    try:\n",
    "        if i['class'][1] == 'dem-count':\n",
    "            h3 = i.find('h3')\n",
    "            spans = h3.findAll('span')\n",
    "            if 'Biden ' in spans[2].contents:\n",
    "                print(f\"Biden has {spans[1].contents[0]} Electoral College votes\")\n",
    "        if i['class'][1] == 'gop-count':\n",
    "            h3 = i.find('h3')\n",
    "            spans = h3.findAll('span')\n",
    "            if 'Trump ' in spans[0].contents:\n",
    "                print(f\"Trump has {spans[1].contents[0]} Electoral College votes\")\n",
    "    except Exception:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on legality:\n",
    "\n",
    "Companies and websites do not seem to appreciate bots. However the Supreme Court ruled that it was legal so exercise your rights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
