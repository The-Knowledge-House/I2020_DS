{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #000;\n",
    "            color: #FFF;\n",
    "            margin: 0px;\n",
    "            padding: 10px 0px 20px 0px;\n",
    "            text-align: center; \n",
    "                \">\n",
    "    <h1 >Week 18 Class 2 01/26</h1>\n",
    "</div>\n",
    "\n",
    "## Objectives for this week:\n",
    "* Data Structuring \n",
    "* Data Cleanup\n",
    "\n",
    "## Todays Agenda\n",
    "* Continuing our code along\n",
    "* Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #000;\n",
    "            color: #FFF;\n",
    "            margin: 0px;\n",
    "            padding: 10px 0px 20px 0px;\n",
    "            text-align: center; \n",
    "                \">\n",
    "    <h1 >Homework Problem</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Given a stream of integers and a window size, calculate the moving average of all integers in the sliding window.\n",
    "\n",
    "Implement the `MovingAverage` class:\n",
    "* `MovingAverage(size)` Initializes the object with the size of the window size.\n",
    "* `next(val)` Returns the moving average of the last size values of the stream.\n",
    "\n",
    "**Example 1:** \n",
    "movingAverage = MovingAverage(3);  \n",
    "movingAverage.next(1); // return 1.0 = 1 / 1  \n",
    "movingAverage.next(10); // return 5.5 = (1 + 10) / 2  \n",
    "movingAverage.next(3); // return 4.66667 = (1 + 10 + 3) / 3  \n",
    "movingAverage.next(5); // return 6.0 = (10 + 3 + 5) / 3  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections \n",
    "\n",
    "class MovingAverage(object):\n",
    "    def __init__(self, size):\n",
    "        \"\"\"\n",
    "        Initialize your data structure here.\n",
    "        :type size: int\n",
    "        \"\"\"\n",
    "        self.max_size = size\n",
    "        self.window = []\n",
    "        \n",
    "\n",
    "    def next(self, val):\n",
    "        \"\"\"\n",
    "        :type val: int\n",
    "        :rtype: float\n",
    "        \"\"\"\n",
    "        if len(self.window) == self.max_size:\n",
    "            self.window.pop(0)\n",
    "        self.window.append(val)\n",
    "        return sum(self.window)/len(self.window)  \n",
    "\n",
    "moving_average = MovingAverage(3)\n",
    "print(moving_average.next(1))# == 1.0\n",
    "print(moving_average.next(10))# == 5.5\n",
    "print(moving_average.next(3))# == 4.666666666666667\n",
    "print(moving_average.next(5))# == 6.0\n",
    "\n",
    "try:\n",
    "    moving_average = MovingAverage(3)\n",
    "    assert(moving_average.next(1) == 1.0)\n",
    "    assert(moving_average.next(10) == 5.5)\n",
    "    assert(moving_average.next(3) == 4.666666666666667)\n",
    "    assert(moving_average.next(5) == 6.0)\n",
    "    moving_average = MovingAverage(5)\n",
    "    assert(moving_average.next(4) == 4.0)\n",
    "    assert(moving_average.next(1) == 2.5)\n",
    "    assert(moving_average.next(10) == 5.0)\n",
    "    assert(moving_average.next(5) == 5.0)\n",
    "    print(\"solution is correct\")\n",
    "except AssertionError:\n",
    "    print(\"solution is incorrect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class MovingAverage(object):\n",
    "    def __init__(self, size):\n",
    "        \"\"\"\n",
    "        Initialize your data structure here.\n",
    "        :type size: int\n",
    "        \"\"\"\n",
    "        self.window = deque(maxlen=size)\n",
    "        \n",
    "\n",
    "    def next(self, val):\n",
    "        \"\"\"\n",
    "        :type val: int\n",
    "        :rtype: float\n",
    "        \"\"\"\n",
    "        self.window.append(val)\n",
    "        return sum(self.window)/len(self.window)  \n",
    "\n",
    "try:\n",
    "    moving_average = MovingAverage(3)\n",
    "    assert(moving_average.next(1) == 1.0)\n",
    "    assert(moving_average.next(10) == 5.5)\n",
    "    assert(moving_average.next(3) == 4.666666666666667)\n",
    "    assert(moving_average.next(5) == 6.0)\n",
    "    moving_average = MovingAverage(5)\n",
    "    assert(moving_average.next(4) == 4.0)\n",
    "    assert(moving_average.next(1) == 2.5)\n",
    "    assert(moving_average.next(10) == 5.0)\n",
    "    assert(moving_average.next(5) == 5.0)\n",
    "    print(\"solution is correct\")\n",
    "except AssertionError:\n",
    "    print(\"solution is incorrect\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[more on deque](https://docs.python.org/3/library/collections.html#collections.deque)** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #000;\n",
    "            color: #FFF;\n",
    "            margin: 0px;\n",
    "            padding: 10px 0px 20px 0px;\n",
    "            text-align: center; \n",
    "                \">\n",
    "    <h1>Books</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start here:\n",
    "[Mathematics for Computer Science](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-042j-mathematics-for-computer-science-fall-2010/readings/MIT6_042JF10_notes.pdf)  \n",
    "[Introduction to Probability](http://www.dartmouth.edu/~chance/teaching_aids/books_articles/probability_book/pdf.html)  \n",
    "[Statistics](https://upload.wikimedia.org/wikipedia/commons/8/82/Statistics.pdf)  \n",
    "[Think Stats (using python)](https://greenteapress.com/thinkstats2/thinkstats2.pdf)  \n",
    "[Think Bayes](https://www.greenteapress.com/thinkbayes/thinkbayes.pdf)  \n",
    "[Probabilistic Programming and Bayesian Methods for Hackers](https://nbviewer.jupyter.org/github/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter1_Introduction/Ch1_Introduction_PyMC3.ipynb)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #000;\n",
    "            color: #FFF;\n",
    "            margin: 0px;\n",
    "            padding: 10px 0px 20px 0px;\n",
    "            text-align: center; \n",
    "                \">\n",
    "    <h1>Code Along</h1>\n",
    "    <h3>Cleaning up dirty data</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some new things we'll cover in this code along:\n",
    "\n",
    "[pandas.DataFrame.apply](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html) - applies a function to rows of a col  \n",
    "[pandas.DataFrame.drop](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html) - drops rows or columns  \n",
    "[pandas.DataFrame.drop_duplicates](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html) - drops duplicates  \n",
    "[pandas.DataFrame.duplicated](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.duplicated.html) - returns True if duplicate  \n",
    "[pandas.DataFrame.fillna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html) - fills NaN values  \n",
    "[pandas.merge](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html) - merges two dfs  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the libraries we'll be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open the `ted_talks.csv` file and generate a dataframe. Then we'll check the top of the `df` to see what we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/ted_talks.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the shape of the `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking info to see other information (like how much RAM our dataset uses and how many non-null entries we have)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see we have 2555 rows but 2531 non-null rows for 'main_speaker'. So let's check that out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['main_speaker'].isna()][[\"description\", \"main_speaker\",\"name\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we fix the \"main_speaker\" column, let's shrink our dataset by removing duplicates. \n",
    "First we need to see how many duplicates we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['url'].duplicated().sort_values(ascending=False)[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['url'].duplicated() == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['url'].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll drop the duplicates using the `df.drop_duplicates` method. \n",
    "\n",
    "Remember, the keyword `inplace` means it will mutate the original `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(df.drop_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates('url', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll drop the `ID` column as it's unnecessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at `published_date` and `film_date`, they're formatted as unix timestamps. We might need a human-readable format.\n",
    "\n",
    "[more on unix timestamps](https://en.wikipedia.org/wiki/Unix_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"published_date\", \"film_date\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how we can turn a unix timestamp into a human-readable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = 1151367060\n",
    "\n",
    "s = datetime.datetime.fromtimestamp(ts)\n",
    "\n",
    "s.strftime(\"%m/%d/%Y, %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting that together, we can create a function that does this for any timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_date(timestamp):\n",
    "    _date = datetime.datetime.fromtimestamp(timestamp)\n",
    "    return _date.strftime(\"%m/%d/%Y, %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can test it with a random timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_date(1151367060)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `df.apply` method to apply that function to each row of a specific column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['film_date'].apply(transform_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing that it works, we can now use that `transform_date` method along with `apply` to create two new columns of human-readable timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['film_date_hr'] = df['film_date'].apply(transform_date)\n",
    "df['published_date_hr'] = df['published_date'].apply(transform_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to change the ordering of the columns, we can use `df.columns.tolist()` to list our columns and then `df.reindex()` to reindex the columns by passing in a list of columns in the order we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reindex(['comments',\n",
    " 'description',\n",
    " 'duration',\n",
    " 'event',\n",
    " 'film_date',\n",
    " 'film_date_hr',\n",
    " 'languages',\n",
    " 'main_speaker',\n",
    " 'name',\n",
    " 'num_speaker',\n",
    " 'published_date',\n",
    " 'published_date_hr',\n",
    " 'ratings',\n",
    " 'related_talks',\n",
    " 'speaker_occupation',\n",
    " 'tags',\n",
    " 'title',\n",
    " 'url',\n",
    " 'views',\n",
    "],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that works by checking the head of the `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll fix the durations, which are in seconds, by converting them to mins and rounding the result to 2 places after the decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration'] = round( df['duration'] / 60, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll fix incorrect values for `languages` and `num_speakers` by replacing erroneous values with `1` since we know there's at least one language translated (english) and there's at least one speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['languages'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['languages'].replace(0, 1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['languages'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['num_speaker'] <= 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"num_speaker\"].replace(0, 1, inplace=True)\n",
    "df[\"num_speaker\"].replace(-1, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we're able to get back to the first issue of `main_speaker` having blanks. We can use `df['main_speaker'].isna()` to check the rows of `main_speaker` that are empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['main_speaker'].isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the `description`, `main_speaker` and `name` columns for all of the blank rows, we see some useful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['main_speaker'].isna()][[\"description\", \"main_speaker\",\"name\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without that useful information, we can always just replace empty values with a default value like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(\"unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['main_speaker'] == 'unknown'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But here, `name` also contains the speaker's name. So we can rip it and then adjust `main_speaker` and `name` accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['name'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['main_speaker'] = df['name'].str.split(':',1).str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['name'] = df['name'].str.split(':',1).str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #000;\n",
    "            color: #FFF;\n",
    "            margin: 0px;\n",
    "            padding: 10px 0px 20px 0px;\n",
    "            text-align: center; \n",
    "                \">\n",
    "    <h1>Lab</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For today's lab, we'll be using the Marvel comic book characters data set available from [538](https://github.com/fivethirtyeight/data/tree/master/comic-characters)\n",
    "\n",
    "The data comes from [Marvel Wikia](http://marvel.wikia.com/Main_Page) and [DC Wikia](http://dc.wikia.com/wiki/Main_Page). Characters were scraped on August 24. Appearance counts were scraped on September 2. The month and year of the first issue each character appeared in was pulled on October 6.\n",
    "\n",
    "The data is split into two files, for DC and Marvel, respectively: `dc-wikia-data.csv` and `marvel-wikia-data.csv`. Each file has the following variables:\n",
    "\n",
    "Variable | Definition\n",
    "---|---------\n",
    "`page_id` | The unique identifier for that characters page within the wikia\n",
    "`name` | The name of the character\n",
    "`urlslug` | The unique url within the wikia that takes you to the character\n",
    "`ID` | The identity status of the character (Secret Identity, Public identity, [on marvel only: No Dual Identity])\n",
    "`ALIGN` | If the character is Good, Bad or Neutral\n",
    "`EYE` | Eye color of the character\n",
    "`HAIR` | Hair color of the character\n",
    "`SEX` | Sex of the character (e.g. Male, Female, etc.)\n",
    "`GSM` | If the character is a gender or sexual minority (e.g. Homosexual characters, bisexual characters)\n",
    "`ALIVE` | If the character is alive or deceased\n",
    "`APPEARANCES` | The number of appareances of the character in comic books (as of Sep. 2, 2014. Number will become increasingly out of date as time goes on.)\n",
    "`FIRST APPEARANCE` | The month and year of the character's first appearance in a comic book, if available\n",
    "`YEAR` | The year of the character's first appearance in a comic book, if available\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the libraries we'll be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open the `marvel-wikia-data.csv` file and generate a dataframe. Then we'll check the top of the `df` to see what we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/marvel-wikia-data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see we have a couple of issues:\n",
    "* The column `names` has, in some cases, both the hero name and their secret identity. In other cases, it has the universe the hero is from (usually Earth-616). We'd like for `name` to be the superhero. If a secret identity name is available, we'd like for that to be in it's own column. We'd also like a column `origin` for the superhero's place of origin (usually Earth-616).\n",
    "* The `urlslug` column is incorrect. We'd like for that to be a complete link. For example, spiderman's wikia link is https://marvel.fandom.com/wiki/Peter_Parker_(Earth-616) but if you use the `Spider-Man_(Peter_Parker)` from the `urlslug` (https://marvel.fandom.com/wiki/Spider-Man_(Peter_Parker), the page redirects to the correct page. You can choose to fix it various different ways but it should be a working link. Use \"https://marvel.fandom.com/wiki/\" as the beginning of your url.\n",
    "* For the column `align`, we'd like for the \"Characters\" part to be removed. We'd like for that column to be categorical (Good, Neutral, Evil or blank).\n",
    "* Same for the columns `EYE`, `HAIR`, `SEX` and `ID`. We want to drop the extraneous data and have simple categories (e.g. for `ID` we want categories [\"Known\",\"Public\", \"Secret\", \"None\"] and for `SEX` we just want [\"Male\", \"Female\",\"Genderfluid\",\"Agender\"]. There's a way shown below that shows the various possible categories.\n",
    "* Some data is in the wrong format. For example, `Year` and `APPEARANCES` are floats but they really should be ints (as you cannot have a non-int number of appearances). \n",
    "* Some data doesn't match up (like the `FIRST APPEARANCE` and `Year` columns might have not be the same year)\n",
    "* Some columns are unnecessary. Some are missing data. Some rows are duplicates. Fix those as necessary.\n",
    "* Some column names are written as uppercase, some are lowercase and some are mixed case. Normalize them so all the column names are in the same format.\n",
    "\n",
    "Fix as many of these issues as you're able to. At the minimum, complete 4 of the above bulletpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_possible_categories(col):\n",
    "    return df.groupby(col).sum()\n",
    "    \n",
    "see_possible_categories('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
