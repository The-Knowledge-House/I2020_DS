{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "higher-circus",
   "metadata": {},
   "source": [
    "<div style=\"background: #000;\n",
    "            color: #FFF;\n",
    "            margin: 0px;\n",
    "            padding: 10px 0px 20px 0px;\n",
    "            text-align: center; \n",
    "                \">\n",
    "    <h1 >Week 22 Lab</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-vertex",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-robertson",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "We'd like to analyze the `SNAP_history_1969_2019.csv` dataset, however it's missing some data. Find the missing values. Fix incorrect entries as well.\n",
    "\n",
    "Some helpful formulas:\n",
    "\n",
    "$ \\texttt{Total Costs} = \\texttt{Total Benefits} + \\texttt{Other Costs} $\n",
    "\n",
    "$ \\texttt{Total Benefits} = \\texttt{Total Costs} - \\texttt{Other Costs} $\n",
    "\n",
    "$ \\texttt{Other Costs} = \\texttt{Total Costs} - \\texttt{Total Benefits} $\n",
    "\n",
    "$ \\texttt{Average Participation} = \\frac{\\texttt{Total Benefits}}{\\texttt{Average Benefits Per Person}}$\n",
    "\n",
    "$ \\texttt{Average Benefits Per Person} = \\frac{\\texttt{Total Benefits}}{\\texttt{Average Participation}}$\n",
    "\n",
    "$ \\texttt{Total Benefits} = \\texttt{Average Benefits Per Person} * \\texttt{Average Participation}$\n",
    "\n",
    "Note: `Average Participation` is in the thousands and all costs  are in the millions.\n",
    "\n",
    "Hint: Think about how we can filter for specific columns that are null and apply a fix for those missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-portrait",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling it s_df to not confuse it with the others \n",
    "# and because `snap_df` is too much to constantly write\n",
    "s_df = pd.read_csv('../datasets/SNAP_history_1969_2019.csv')\n",
    "s_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df[s_df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-benefit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "greek-bunny",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "We'd like to do some analysis on our `grades.csv` dataset.\n",
    "\n",
    "Using the following dataframe, do some exploratory analysis and then plot, at least, one chart using matplotlib or seaborn (with title, axes labeled and anything else that would make it look professional).\n",
    "\n",
    "Hint: \n",
    "We've seen how to plot box plots, scatter plots, line charts, bar charts, histograms and even more complicated charts like heatmaps of the correlations. Refer to your notes and try to come up with a useful chart that demonstrates a relationship we might like to explore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling it g_df to not confuse it with the others \n",
    "# and because `grades_df` is too much to constantly write\n",
    "g_df = pd.read_csv('../datasets/grades.csv')\n",
    "g_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-internship",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "answering-scenario",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "Exercise 3 was a logistic regression on the Titanic dataset. It will be given as a guided project instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-vintage",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
